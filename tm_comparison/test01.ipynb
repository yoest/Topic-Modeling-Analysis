{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from ris_evaluation.evaluator import Evaluator\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, documents_df) -> None:\n",
    "        self.documents_df = documents_df.copy()\n",
    "        self.documents = self.documents_df['document'].tolist()\n",
    "        self.labels = self.documents_df['class_name'].tolist()\n",
    "\n",
    "    def train(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_output(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_results_df(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_words_for_topics(self, topics):\n",
    "        words_by_topics = {}\n",
    "        for idx, topic in enumerate(topics):\n",
    "            words = self.documents_df.iloc[idx]['document'].split()\n",
    "\n",
    "            if topic not in words_by_topics:\n",
    "                words_by_topics[topic] = {}\n",
    "\n",
    "            for word in words:\n",
    "                if word not in words_by_topics[topic]:\n",
    "                    words_by_topics[topic][word] = 0\n",
    "\n",
    "                words_by_topics[topic][word] += 1\n",
    "\n",
    "        return words_by_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDAModel(Model):\n",
    "\n",
    "    def __init__(self, documents_df) -> None:\n",
    "        super().__init__(documents_df)\n",
    "        self.n_topics = len(set(self.labels))\n",
    "\n",
    "    def train(self):\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        X = self.vectorizer.fit_transform(self.documents)\n",
    "\n",
    "        self.lda = LatentDirichletAllocation(n_components=self.n_topics)\n",
    "        self.lda.fit(X)\n",
    "\n",
    "    def get_results_df(self):\n",
    "        results_df = pd.DataFrame()\n",
    "        results_df['document'] = self.documents\n",
    "        results_df['y_true'] = self.labels\n",
    "\n",
    "        X = self.vectorizer.transform(self.documents)\n",
    "        results_df['y_pred'] = self.lda.transform(X).argmax(axis=1)\n",
    "        results_df['y_pred_highest_proba'] = self.lda.transform(X).max(axis=1)\n",
    "        return results_df\n",
    "\n",
    "    def get_output(self):\n",
    "        topics = []\n",
    "        for topic in self.lda.components_:\n",
    "            topic_words = []\n",
    "            for i in topic.argsort()[-10:]:\n",
    "                topic_words.append(self.vectorizer.get_feature_names_out()[i])\n",
    "            topics.append(topic_words)\n",
    "\n",
    "        return {\n",
    "            \"topics\": topics,\n",
    "            \"topic-document-matrix\": None,\n",
    "            \"topic-word-matrix\": None,\n",
    "            \"test-topic-document-matrix\": None\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTopicModel(Model):\n",
    "\n",
    "    def __init__(self, documents_df) -> None:\n",
    "        super().__init__(documents_df)\n",
    "        self.n_topics = len(set(self.labels)) + 1  # +1 for outliers\n",
    "\n",
    "    def train(self):\n",
    "        self.bert_model = BERTopic(language=\"english\", calculate_probabilities=True, nr_topics=self.n_topics)\n",
    "        self.topics, self.probs = self.bert_model.fit_transform(self.documents)\n",
    "\n",
    "    def get_results_df(self):\n",
    "        results_df = pd.DataFrame()\n",
    "        results_df['document'] = self.documents\n",
    "        results_df['y_true'] = self.labels\n",
    "\n",
    "        results_df['y_pred'] = self.topics\n",
    "        results_df['y_pred_highest_proba'] = np.max(self.probs, axis=1)\n",
    "\n",
    "        relevant_results_df = results_df[results_df['y_pred'] != -1]\n",
    "        return relevant_results_df\n",
    "    \n",
    "    def get_output(self):\n",
    "        return {\n",
    "            \"topics\": [item for item in self.bert_model.get_topic_info()[\"Representation\"]],\n",
    "            \"topic-document-matrix\": self.probs.transpose(),\n",
    "            \"topic-word-matrix\": self.bert_model.c_tf_idf_,\n",
    "            \"test-topic-document-matrix\": self.probs.transpose()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_df(dataset_names, models, n_iterations=10):\n",
    "    metrics_df = pd.DataFrame()\n",
    "    idx = 0\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # -- Get dataset\n",
    "        documents_df = pd.read_csv(f'../datasets/data/{dataset}/documents.csv')\n",
    "\n",
    "        for model in models:\n",
    "            avg_results = {}\n",
    "\n",
    "            for i in range(n_iterations):\n",
    "                print(f'Iteration {i+1}/{n_iterations} for {dataset} and {model.__name__}', end='\\r')\n",
    "\n",
    "                # -- Train model\n",
    "                trained_model = model(documents_df)\n",
    "                trained_model.train()\n",
    "\n",
    "                model_output = trained_model.get_output()\n",
    "\n",
    "                # -- Evaluate model\n",
    "                evaluator = Evaluator(model_output)\n",
    "                results_df = trained_model.get_results_df()\n",
    "\n",
    "                words_by_extracted_topics = trained_model.get_words_for_topics(results_df['y_pred'].tolist())\n",
    "                words_by_class = trained_model.get_words_for_topics(results_df['y_true'].tolist())\n",
    "\n",
    "                coherence = evaluator.compute_coherence()\n",
    "                diversity = evaluator.compute_diversity()\n",
    "                supervised_correlation = evaluator.compute_supervised_correlation(words_by_extracted_topics, words_by_class)\n",
    "\n",
    "                # -- Average results\n",
    "                for coherence_type, coherence_value in coherence.items():\n",
    "                    if coherence_type not in avg_results:\n",
    "                        avg_results[f'coherence_{coherence_type}'] = []\n",
    "                    avg_results[f'coherence_{coherence_type}'].append(coherence_value)\n",
    "                \n",
    "                avg_results['diversity'] = avg_results.get('diversity', []) + [diversity]\n",
    "                avg_results['supervised_correlation'] = avg_results.get('supervised_correlation', []) + [supervised_correlation]\n",
    "\n",
    "            for key, value in avg_results.items():\n",
    "                avg_results[key] = np.mean(value)\n",
    "\n",
    "            metrics_results = {}\n",
    "            metrics_results['dataset'] = dataset\n",
    "            metrics_results['model'] = trained_model.__class__.__name__\n",
    "            for key, value in avg_results.items():\n",
    "                metrics_results[key] = [value]\n",
    "\n",
    "            metrics_df = pd.concat([metrics_df, pd.DataFrame(metrics_results, index=[idx])])\n",
    "            idx += 1\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Iteration 3/5 for M10 and BERTopicModel\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yorest/miniconda3/envs/nlp/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/yorest/miniconda3/envs/nlp/lib/python3.9/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5/5 for M10 and BERTopicModel\r"
     ]
    }
   ],
   "source": [
    "metrics_df = compute_metrics_df(dataset_names=[\n",
    "    'BBC_News',\n",
    "    '20NewsGroup',\n",
    "    'DBLP',\n",
    "    'M10',\n",
    "], models=[\n",
    "    LDAModel,\n",
    "    BERTopicModel\n",
    "], n_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>coherence_c_v</th>\n",
       "      <th>coherence_c_uci</th>\n",
       "      <th>coherence_c_npmi</th>\n",
       "      <th>coherence_u_mass</th>\n",
       "      <th>diversity</th>\n",
       "      <th>supervised_correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBC_News</td>\n",
       "      <td>LDAModel</td>\n",
       "      <td>0.507245</td>\n",
       "      <td>-0.224381</td>\n",
       "      <td>0.026653</td>\n",
       "      <td>-2.237404</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.824987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBC_News</td>\n",
       "      <td>BERTopicModel</td>\n",
       "      <td>0.480479</td>\n",
       "      <td>-0.194804</td>\n",
       "      <td>0.021948</td>\n",
       "      <td>-2.220241</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.701449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20NewsGroup</td>\n",
       "      <td>LDAModel</td>\n",
       "      <td>0.600076</td>\n",
       "      <td>0.660461</td>\n",
       "      <td>0.091718</td>\n",
       "      <td>-1.767074</td>\n",
       "      <td>0.743000</td>\n",
       "      <td>0.611222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20NewsGroup</td>\n",
       "      <td>BERTopicModel</td>\n",
       "      <td>0.510362</td>\n",
       "      <td>0.175887</td>\n",
       "      <td>0.067621</td>\n",
       "      <td>-2.255179</td>\n",
       "      <td>0.827619</td>\n",
       "      <td>0.382447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBLP</td>\n",
       "      <td>LDAModel</td>\n",
       "      <td>0.566795</td>\n",
       "      <td>0.094171</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>-1.931211</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.612566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DBLP</td>\n",
       "      <td>BERTopicModel</td>\n",
       "      <td>0.555418</td>\n",
       "      <td>-0.304531</td>\n",
       "      <td>0.022946</td>\n",
       "      <td>-2.246640</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.299963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M10</td>\n",
       "      <td>LDAModel</td>\n",
       "      <td>0.457851</td>\n",
       "      <td>-0.061817</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>-2.270753</td>\n",
       "      <td>0.838000</td>\n",
       "      <td>0.520814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M10</td>\n",
       "      <td>BERTopicModel</td>\n",
       "      <td>0.515526</td>\n",
       "      <td>-2.204118</td>\n",
       "      <td>-0.050275</td>\n",
       "      <td>-2.546092</td>\n",
       "      <td>0.914545</td>\n",
       "      <td>0.626878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset          model  coherence_c_v  coherence_c_uci  \\\n",
       "0     BBC_News       LDAModel       0.507245        -0.224381   \n",
       "1     BBC_News  BERTopicModel       0.480479        -0.194804   \n",
       "2  20NewsGroup       LDAModel       0.600076         0.660461   \n",
       "3  20NewsGroup  BERTopicModel       0.510362         0.175887   \n",
       "4         DBLP       LDAModel       0.566795         0.094171   \n",
       "5         DBLP  BERTopicModel       0.555418        -0.304531   \n",
       "6          M10       LDAModel       0.457851        -0.061817   \n",
       "7          M10  BERTopicModel       0.515526        -2.204118   \n",
       "\n",
       "   coherence_c_npmi  coherence_u_mass  diversity  supervised_correlation  \n",
       "0          0.026653         -2.237404   0.920000                0.824987  \n",
       "1          0.021948         -2.220241   0.856667                0.701449  \n",
       "2          0.091718         -1.767074   0.743000                0.611222  \n",
       "3          0.067621         -2.255179   0.827619                0.382447  \n",
       "4          0.038986         -1.931211   0.830000                0.612566  \n",
       "5          0.022946         -2.246640   0.760000                0.299963  \n",
       "6          0.016673         -2.270753   0.838000                0.520814  \n",
       "7         -0.050275         -2.546092   0.914545                0.626878  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}\n",
      "\\toprule\n",
      "dataset & model & coherence_c_v & coherence_c_uci & coherence_c_npmi & coherence_u_mass & diversity & supervised_correlation \\\\\n",
      "\\midrule\n",
      "BBC_News & LDAModel & 0.507245 & -0.224381 & 0.026653 & -2.237404 & 0.920000 & 0.824987 \\\\\n",
      "BBC_News & BERTopicModel & 0.480479 & -0.194804 & 0.021948 & -2.220241 & 0.856667 & 0.701449 \\\\\n",
      "20NewsGroup & LDAModel & 0.600076 & 0.660461 & 0.091718 & -1.767074 & 0.743000 & 0.611222 \\\\\n",
      "20NewsGroup & BERTopicModel & 0.510362 & 0.175887 & 0.067621 & -2.255179 & 0.827619 & 0.382447 \\\\\n",
      "DBLP & LDAModel & 0.566795 & 0.094171 & 0.038986 & -1.931211 & 0.830000 & 0.612566 \\\\\n",
      "DBLP & BERTopicModel & 0.555418 & -0.304531 & 0.022946 & -2.246640 & 0.760000 & 0.299963 \\\\\n",
      "M10 & LDAModel & 0.457851 & -0.061817 & 0.016673 & -2.270753 & 0.838000 & 0.520814 \\\\\n",
      "M10 & BERTopicModel & 0.515526 & -2.204118 & -0.050275 & -2.546092 & 0.914545 & 0.626878 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics_df.to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
