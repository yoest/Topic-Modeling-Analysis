{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yorest/miniconda3/envs/nlp/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/yorest/miniconda3/envs/nlp/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/yorest/miniconda3/envs/nlp/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/yorest/miniconda3/envs/nlp/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from ris_evaluation.evaluator import Evaluator\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "\n",
    "from gensim import corpora\n",
    "import gensim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, dataset_name: str) -> None:\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "        self.documents_df = pd.read_csv(f'../../datasets/data/{dataset_name}/documents.csv')\n",
    "        self.documents_df = self.documents_df\n",
    "\n",
    "        self.documents = self.documents_df['document'].tolist()\n",
    "        self.labels = self.documents_df['class_name'].tolist()\n",
    "\n",
    "        self.labels_df = pd.read_csv(f'../../datasets/data/{dataset_name}/labels.csv')\n",
    "        self.defined_keywords = [keywords.split(' ') for keywords in self.labels_df['class_keywords'].tolist()]\n",
    "\n",
    "        self.num_topics = len(set(self.labels))\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\" Train the model \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_output(self):\n",
    "        \"\"\" Get the output of the model on the OCTIS format \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_results_df(self):\n",
    "        \"\"\" Get the results of the model on a DataFrame \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_words_for_topics(self, topics):\n",
    "        \"\"\" Get the words for each topic from the documents\n",
    "\n",
    "        Args:\n",
    "            topics (list): The topics for each document\n",
    "\n",
    "        Returns:\n",
    "            dict: The words for each topic\n",
    "        \"\"\"\n",
    "        words_by_topics = {}\n",
    "        for idx, topic in enumerate(topics):\n",
    "            words = self.documents_df.iloc[idx]['document'].split()\n",
    "\n",
    "            if topic not in words_by_topics:\n",
    "                words_by_topics[topic] = {}\n",
    "\n",
    "            for word in words:\n",
    "                if word not in words_by_topics[topic]:\n",
    "                    words_by_topics[topic][word] = 0\n",
    "\n",
    "                words_by_topics[topic][word] += 1\n",
    "\n",
    "        return words_by_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDAModel(Model):\n",
    "\n",
    "    def __init__(self, dataset_name: str) -> None:\n",
    "        super().__init__(dataset_name)\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\" See the documentation of the parent class \"\"\"\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        X = self.vectorizer.fit_transform(self.documents)\n",
    "\n",
    "        self.lda = LatentDirichletAllocation(n_components=self.num_topics)\n",
    "        self.lda.fit(X)\n",
    "\n",
    "    def get_results_df(self):\n",
    "        \"\"\" See the documentation of the parent class \"\"\"\n",
    "        results_df = pd.DataFrame()\n",
    "        results_df['document'] = self.documents\n",
    "        results_df['y_true'] = self.labels\n",
    "\n",
    "        X = self.vectorizer.transform(self.documents)\n",
    "        results_df['y_pred'] = self.lda.transform(X).argmax(axis=1)\n",
    "        results_df['y_pred_highest_proba'] = self.lda.transform(X).max(axis=1)\n",
    "        return results_df\n",
    "\n",
    "    def get_output(self):\n",
    "        \"\"\" See the documentation of the parent class \"\"\"\n",
    "        topics = []\n",
    "        for topic in self.lda.components_:\n",
    "            topic_words = []\n",
    "            for i in topic.argsort()[-10:]:\n",
    "                topic_words.append(self.vectorizer.get_feature_names_out()[i])\n",
    "            topics.append(topic_words)\n",
    "\n",
    "        return {\n",
    "            \"topics\": topics,\n",
    "            \"topic-document-matrix\": None,\n",
    "            \"topic-word-matrix\": None,\n",
    "            \"test-topic-document-matrix\": None\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTopicModel(Model):\n",
    "\n",
    "    def __init__(self, dataset_name: str) -> None:\n",
    "        super().__init__(dataset_name)\n",
    "        self.num_topics = len(set(self.labels)) + 1  # +1 for outliers\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\" See the documentation of the parent class \"\"\"\n",
    "        self.bert_model = BERTopic(language=\"english\", calculate_probabilities=True, nr_topics=self.num_topics)\n",
    "        self.topics, self.probs = self.bert_model.fit_transform(self.documents)\n",
    "\n",
    "    def get_results_df(self):\n",
    "        \"\"\" See the documentation of the parent class \"\"\"\n",
    "        results_df = pd.DataFrame()\n",
    "        results_df['document'] = self.documents\n",
    "        results_df['y_true'] = self.labels\n",
    "\n",
    "        results_df['y_pred'] = self.topics\n",
    "        results_df['y_pred_highest_proba'] = np.max(self.probs, axis=1)\n",
    "\n",
    "        relevant_results_df = results_df[results_df['y_pred'] != -1]\n",
    "        return relevant_results_df\n",
    "    \n",
    "    def get_output(self):\n",
    "        \"\"\" See the documentation of the parent class \"\"\"\n",
    "        return {\n",
    "            \"topics\": [item for item in self.bert_model.get_topic_info()[\"Representation\"]],\n",
    "            \"topic-document-matrix\": self.probs.transpose(),\n",
    "            \"topic-word-matrix\": self.bert_model.c_tf_idf_,\n",
    "            \"test-topic-document-matrix\": self.probs.transpose()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuidedLDAModel(Model):\n",
    "\n",
    "    def __init__(self, dataset_name: str) -> None:\n",
    "        super().__init__(dataset_name)\n",
    "\n",
    "    def train(self) -> None:\n",
    "        \"\"\" See the documentation of the parent class \"\"\"\n",
    "        self.texts = [document.split(' ') for document in self.documents]\n",
    "        \n",
    "        self.dictionary = corpora.Dictionary(self.texts)\n",
    "        self.corpus = [self.dictionary.doc2bow(text) for text in self.texts]\n",
    "\n",
    "        priors = {}\n",
    "        for idx, keywords in enumerate(self.defined_keywords):\n",
    "            for keyword in keywords:\n",
    "                priors[keyword] = idx\n",
    "\n",
    "        eta = np.full(shape=(self.num_topics, len(self.dictionary)), fill_value=1) # create a (ntopics, nterms) matrix and fill with 1\n",
    "        for word, topic in priors.items(): # for each word in the list of priors\n",
    "            keyindex = [index for index,term in self.dictionary.items() if term == word] # look up the word in the dictionary\n",
    "            if (len(keyindex) > 0): # if it's in the dictionary\n",
    "                eta[topic,keyindex[0]] = 1e7  # put a large number in there\n",
    "        eta = np.divide(eta, eta.sum(axis=0)) # normalize so that the probabilities sum to 1 over all topics\n",
    "\n",
    "        with (np.errstate(divide='ignore')):  # ignore divide-by-zero warnings\n",
    "            self.model = gensim.models.ldamodel.LdaModel(\n",
    "                corpus=self.corpus, id2word=self.dictionary, num_topics=self.num_topics,\n",
    "                random_state=42, chunksize=100, eta=eta,\n",
    "                eval_every=-1, update_every=1,\n",
    "                passes=150, alpha='auto', per_word_topics=True)\n",
    "\n",
    "    def get_results_df(self):\n",
    "        \"\"\" See the documentation of the parent class \"\"\"\n",
    "        self.results_df = pd.DataFrame()\n",
    "        self.results_df['document'] = self.documents\n",
    "        self.results_df['y_true'] = self.documents_df['class_name'].tolist()\n",
    "\n",
    "        scores = [[value[1] for value in score_values[0]] for score_values in self.model[self.corpus]]\n",
    "        self.results_df['y_pred'] = [np.argmax(score) for score in scores]\n",
    "        self.results_df['y_pred_highest_proba'] = [np.max(score) for score in scores]\n",
    "        return self.results_df\n",
    "    \n",
    "    def get_output(self):\n",
    "        \"\"\" See the documentation of the parent class \"\"\"\n",
    "        topics = [self.model.show_topic(topicid, topn=10) for topicid in range(self.num_topics)]\n",
    "        topics = [[word for word, _ in topic] for topic in topics]\n",
    "\n",
    "        return {\n",
    "            \"topics\": topics,\n",
    "            \"topic-document-matrix\": None,\n",
    "            \"topic-word-matrix\": None,\n",
    "            \"test-topic-document-matrix\": None\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuidedBERTopicModel(BERTopicModel):\n",
    "\n",
    "    def __init__(self, dataset_name: str) -> None:\n",
    "        super().__init__(dataset_name)\n",
    "\n",
    "    def train(self) -> None:\n",
    "        \"\"\" See the documentation of the parent class \"\"\"\n",
    "        umap = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', low_memory=False, random_state=0)\n",
    "        self.bert_model = BERTopic(language=\"english\", calculate_probabilities=True, nr_topics=self.num_topics, umap_model=umap, seed_topic_list=self.defined_keywords)\n",
    "        self.topics, self.probs = self.bert_model.fit_transform(self.documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_df(dataset_name: str, models: list, n_iterations:int=10, load_from_file:bool=False):\n",
    "    \"\"\" Compute the metrics for the given datasets and models\n",
    "\n",
    "    Args:\n",
    "        dataset_name (str): The name of the dataset\n",
    "        models (list): The list of models\n",
    "        n_iterations (int, optional): The number of iterations. Defaults to 10.\n",
    "        load_from_file (bool, optional): Whether to load the results from file or not. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The metrics DataFrame\n",
    "    \"\"\"\n",
    "    if load_from_file:\n",
    "        return pd.read_csv(f'./results/{dataset_name}_metrics.csv')\n",
    "\n",
    "    metrics_df = pd.DataFrame()\n",
    "    idx = 0\n",
    "\n",
    "    for model in models:\n",
    "        avg_results = {}\n",
    "\n",
    "        for i in range(n_iterations):\n",
    "            print(f'Iteration {i+1}/{n_iterations} for {dataset_name} and {model.__name__}', end='\\r')\n",
    "\n",
    "            # -- Train model\n",
    "            trained_model = model(dataset_name)\n",
    "            trained_model.train()\n",
    "\n",
    "            model_output = trained_model.get_output()\n",
    "\n",
    "            # -- Evaluate model\n",
    "            evaluator = Evaluator(model_output)\n",
    "            results_df = trained_model.get_results_df()\n",
    "\n",
    "            words_by_extracted_topics = trained_model.get_words_for_topics(results_df['y_pred'].tolist())\n",
    "            words_by_class = trained_model.get_words_for_topics(results_df['y_true'].tolist())\n",
    "\n",
    "            coherence = evaluator.compute_coherence()\n",
    "            diversity = evaluator.compute_diversity()\n",
    "            supervised_correlation = evaluator.compute_supervised_correlation(words_by_extracted_topics, words_by_class)\n",
    "\n",
    "            # -- Average results\n",
    "            for coherence_type, coherence_value in coherence.items():\n",
    "                if coherence_type not in avg_results:\n",
    "                    avg_results[f'coherence_{coherence_type}'] = []\n",
    "                avg_results[f'coherence_{coherence_type}'].append(coherence_value)\n",
    "            \n",
    "            avg_results['diversity'] = avg_results.get('diversity', []) + [diversity]\n",
    "            avg_results['supervised_correlation'] = avg_results.get('supervised_correlation', []) + [supervised_correlation]\n",
    "\n",
    "        for key, value in avg_results.items():\n",
    "            avg_results[key] = np.mean(value)\n",
    "\n",
    "        metrics_results = {}\n",
    "        metrics_results['dataset'] = dataset_name\n",
    "        metrics_results['model'] = trained_model.__class__.__name__\n",
    "        for key, value in avg_results.items():\n",
    "            metrics_results[key] = [value]\n",
    "\n",
    "        metrics_df = pd.concat([metrics_df, pd.DataFrame(metrics_results, index=[idx])])\n",
    "        idx += 1\n",
    "\n",
    "    metrics_df.to_csv(f'./results/{dataset_name}_metrics.csv', index=False)\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LDAModel, BERTopicModel, GuidedLDAModel, GuidedBERTopicModel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBC News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}\n",
      "\\toprule\n",
      "dataset & model & coherence_c_v & coherence_c_uci & coherence_c_npmi & coherence_u_mass & diversity & supervised_correlation \\\\\n",
      "\\midrule\n",
      "BBC_News & LDAModel & 0.493955 & 0.279265 & 0.040366 & -2.368924 & 0.920000 & 0.760189 \\\\\n",
      "BBC_News & BERTopicModel & 0.433929 & -0.419129 & 0.002830 & -2.499619 & 0.840000 & 0.627419 \\\\\n",
      "BBC_News & GuidedLDAModel & 0.498162 & 0.082306 & 0.037583 & -2.235177 & 0.920000 & 0.588504 \\\\\n",
      "BBC_News & GuidedBERTopicModel & 0.490397 & -0.188388 & 0.026225 & -2.232617 & 0.883333 & 0.922348 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>coherence_c_v</th>\n",
       "      <th>coherence_c_uci</th>\n",
       "      <th>coherence_c_npmi</th>\n",
       "      <th>coherence_u_mass</th>\n",
       "      <th>diversity</th>\n",
       "      <th>supervised_correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBC_News</td>\n",
       "      <td>LDAModel</td>\n",
       "      <td>0.493955</td>\n",
       "      <td>0.279265</td>\n",
       "      <td>0.040366</td>\n",
       "      <td>-2.368924</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.760189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBC_News</td>\n",
       "      <td>BERTopicModel</td>\n",
       "      <td>0.433929</td>\n",
       "      <td>-0.419129</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>-2.499619</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.627419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBC_News</td>\n",
       "      <td>GuidedLDAModel</td>\n",
       "      <td>0.498162</td>\n",
       "      <td>0.082306</td>\n",
       "      <td>0.037583</td>\n",
       "      <td>-2.235177</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.588504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBC_News</td>\n",
       "      <td>GuidedBERTopicModel</td>\n",
       "      <td>0.490397</td>\n",
       "      <td>-0.188388</td>\n",
       "      <td>0.026225</td>\n",
       "      <td>-2.232617</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.922348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset                model  coherence_c_v  coherence_c_uci  \\\n",
       "0  BBC_News             LDAModel       0.493955         0.279265   \n",
       "1  BBC_News        BERTopicModel       0.433929        -0.419129   \n",
       "2  BBC_News       GuidedLDAModel       0.498162         0.082306   \n",
       "3  BBC_News  GuidedBERTopicModel       0.490397        -0.188388   \n",
       "\n",
       "   coherence_c_npmi  coherence_u_mass  diversity  supervised_correlation  \n",
       "0          0.040366         -2.368924   0.920000                0.760189  \n",
       "1          0.002830         -2.499619   0.840000                0.627419  \n",
       "2          0.037583         -2.235177   0.920000                0.588504  \n",
       "3          0.026225         -2.232617   0.883333                0.922348  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_news_metrics_df = compute_metrics_df(dataset_name='BBC_News', models=models, n_iterations=5, load_from_file=True)\n",
    "print(bbc_news_metrics_df.to_latex(index=False))\n",
    "bbc_news_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20NewsGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}roup and GuidedBERTopicModel\n",
      "\\toprule\n",
      "dataset & model & coherence_c_v & coherence_c_uci & coherence_c_npmi & coherence_u_mass & diversity & supervised_correlation \\\\\n",
      "\\midrule\n",
      "20NewsGroup & LDAModel & 0.603940 & 0.673476 & 0.096662 & -1.883472 & 0.761000 & 0.401317 \\\\\n",
      "20NewsGroup & BERTopicModel & 0.472277 & 0.125097 & 0.053755 & -2.306378 & 0.803810 & 0.268840 \\\\\n",
      "20NewsGroup & GuidedLDAModel & 0.462860 & -0.205873 & 0.025873 & -2.436411 & 0.985000 & 0.361511 \\\\\n",
      "20NewsGroup & GuidedBERTopicModel & 0.528895 & 0.203075 & 0.071613 & -2.263779 & 0.814286 & 0.318357 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>coherence_c_v</th>\n",
       "      <th>coherence_c_uci</th>\n",
       "      <th>coherence_c_npmi</th>\n",
       "      <th>coherence_u_mass</th>\n",
       "      <th>diversity</th>\n",
       "      <th>supervised_correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20NewsGroup</td>\n",
       "      <td>LDAModel</td>\n",
       "      <td>0.603940</td>\n",
       "      <td>0.673476</td>\n",
       "      <td>0.096662</td>\n",
       "      <td>-1.883472</td>\n",
       "      <td>0.761000</td>\n",
       "      <td>0.401317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20NewsGroup</td>\n",
       "      <td>BERTopicModel</td>\n",
       "      <td>0.472277</td>\n",
       "      <td>0.125097</td>\n",
       "      <td>0.053755</td>\n",
       "      <td>-2.306378</td>\n",
       "      <td>0.803810</td>\n",
       "      <td>0.268840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20NewsGroup</td>\n",
       "      <td>GuidedLDAModel</td>\n",
       "      <td>0.462860</td>\n",
       "      <td>-0.205873</td>\n",
       "      <td>0.025873</td>\n",
       "      <td>-2.436411</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.361511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20NewsGroup</td>\n",
       "      <td>GuidedBERTopicModel</td>\n",
       "      <td>0.528895</td>\n",
       "      <td>0.203075</td>\n",
       "      <td>0.071613</td>\n",
       "      <td>-2.263779</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.318357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset                model  coherence_c_v  coherence_c_uci  \\\n",
       "0  20NewsGroup             LDAModel       0.603940         0.673476   \n",
       "1  20NewsGroup        BERTopicModel       0.472277         0.125097   \n",
       "2  20NewsGroup       GuidedLDAModel       0.462860        -0.205873   \n",
       "3  20NewsGroup  GuidedBERTopicModel       0.528895         0.203075   \n",
       "\n",
       "   coherence_c_npmi  coherence_u_mass  diversity  supervised_correlation  \n",
       "0          0.096662         -1.883472   0.761000                0.401317  \n",
       "1          0.053755         -2.306378   0.803810                0.268840  \n",
       "2          0.025873         -2.436411   0.985000                0.361511  \n",
       "3          0.071613         -2.263779   0.814286                0.318357  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_metrics_df = compute_metrics_df(dataset_name='20NewsGroup', models=models, n_iterations=5, load_from_file=False)\n",
    "print(newsgroups_metrics_df.to_latex(index=False))\n",
    "newsgroups_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_metrics_df = compute_metrics_df(dataset_name='DBLP', models=models, n_iterations=5, load_from_file=False)\n",
    "print(dblp_metrics_df.to_latex(index=False))\n",
    "dblp_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m10_metrics_df = compute_metrics_df(dataset_name='M10', models=models, n_iterations=5, load_from_file=False)\n",
    "print(m10_metrics_df.to_latex(index=False))\n",
    "m10_metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
