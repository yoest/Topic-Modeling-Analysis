{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './vONTSS/src/topicmodeling')\n",
    "from vONTSS.src.topicmodeling.model import TopicModel\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from ris_evaluation.evaluator import Evaluator\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df = pd.read_csv('../../datasets/data/BBC_News/documents.csv')\n",
    "documents_df = documents_df\n",
    "\n",
    "documents = documents_df['document'].tolist()\n",
    "labels = documents_df['class_name'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yorest/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/yorest/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/yorest/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yorest/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 279\n",
      "None\n",
      "(2255, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yorest/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/distributions/distribution.py:51: UserWarning: <class 'hyperspherical_vae.distributions.hyperspherical_uniform.HypersphericalUniform'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n",
      "/Users/yorest/Documents/code/Sinch-TMC/topic_modeling/vontss/vONTSS/src/topicmodeling/model.py:248: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  z = self.h_to_z(self.temp * z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612.1034749348959 0.01490381391098102\n",
      "595.4284125434028 0.014910612669255998\n",
      "574.7296176486545 0.014932810018459955\n",
      "535.0142042371962 0.014993125572800636\n",
      "481.87308078342016 0.015151851500074068\n",
      "432.47664727105035 0.015590272843837738\n",
      "391.8635660807292 0.016923486151629023\n",
      "362.1978047688802 0.020926619776421122\n",
      "341.7607133653429 0.028936034068465233\n",
      "327.96185980902777 0.03698814163605372\n",
      "320.233654446072 0.0426334829794036\n",
      "315.5075446234809 0.04598445693651835\n",
      "312.55318535698785 0.04803348291251394\n",
      "311.4675767686632 0.0481696981522772\n",
      "310.18870713975696 0.04812121598256959\n",
      "309.35369873046875 0.04824209296041065\n",
      "309.27425977918836 0.04802027179135217\n",
      "309.60611131456164 0.04795724981360965\n",
      "308.7753380669488 0.047890844030512705\n",
      "308.902099609375 0.047843069252040654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yorest/Documents/code/Sinch-TMC/topic_modeling/vontss/vONTSS/src/topicmodeling/model.py:444: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.z = self.model.h_to_z(z_mean).detach().numpy()\n"
     ]
    }
   ],
   "source": [
    "topic_model = TopicModel(numb_embeddings=len(set(labels)))\n",
    "\n",
    "model_output = topic_model.train_model(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yorest/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/yorest/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/yorest/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yorest/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 279\n",
      "None\n",
      "(2255, 100)\n",
      "548.3872680664062 0.014902719193034701\n",
      "537.5518120659722 0.01490252972063091\n",
      "519.8612060546875 0.014908857747084565\n",
      "483.48448350694446 0.014933726957274808\n",
      "441.6279568142361 0.015004901318914361\n",
      "403.2815212673611 0.015123276143438287\n",
      "377.80397542317706 0.015362117336028151\n",
      "359.9303944905599 0.015805069771077897\n",
      "348.9084303114149 0.016605158026019733\n",
      "338.67858547634546 0.017889418328801792\n",
      "331.7918412950304 0.019246094135774508\n",
      "325.8552059597439 0.020924924148453608\n",
      "323.06672837999133 0.022445353575878672\n",
      "319.86077372233075 0.023797170776459906\n",
      "315.940924750434 0.02516086358163092\n",
      "315.2869160970052 0.026125319716003206\n",
      "314.50060017903644 0.02639101631939411\n",
      "313.9137674967448 0.02669058781531122\n",
      "313.1543426513672 0.026675703417923715\n",
      "313.8746100531684 0.02672312677734428\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_pred_highest_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit shelf combine medium player phone gaming g...</td>\n",
       "      <td>tech</td>\n",
       "      <td>0</td>\n",
       "      <td>0.413473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bid hope join host apply host tournament aim r...</td>\n",
       "      <td>sport</td>\n",
       "      <td>2</td>\n",
       "      <td>0.326201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lord wrong detainee straw straw attack decisio...</td>\n",
       "      <td>politics</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leak answer minister explain budget detail pri...</td>\n",
       "      <td>politics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>delight manager pay tribute goal striker beat ...</td>\n",
       "      <td>sport</td>\n",
       "      <td>0</td>\n",
       "      <td>0.320624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>rock clean steer clear bad language front awar...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>comedy meet sequel meet parent top week movie ...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>join rare group actress nominate oscar star fo...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>police chief back move chief back introduction...</td>\n",
       "      <td>politics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>answer call grant extra decide compete world c...</td>\n",
       "      <td>sport</td>\n",
       "      <td>2</td>\n",
       "      <td>0.339601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               document         y_true  \\\n",
       "0     hit shelf combine medium player phone gaming g...           tech   \n",
       "1     bid hope join host apply host tournament aim r...          sport   \n",
       "2     lord wrong detainee straw straw attack decisio...       politics   \n",
       "3     leak answer minister explain budget detail pri...       politics   \n",
       "4     delight manager pay tribute goal striker beat ...          sport   \n",
       "...                                                 ...            ...   \n",
       "2220  rock clean steer clear bad language front awar...  entertainment   \n",
       "2221  comedy meet sequel meet parent top week movie ...  entertainment   \n",
       "2222  join rare group actress nominate oscar star fo...  entertainment   \n",
       "2223  police chief back move chief back introduction...       politics   \n",
       "2224  answer call grant extra decide compete world c...          sport   \n",
       "\n",
       "      y_pred  y_pred_highest_proba  \n",
       "0          0              0.413473  \n",
       "1          2              0.326201  \n",
       "2          1              0.267395  \n",
       "3          0              0.339056  \n",
       "4          0              0.320624  \n",
       "...      ...                   ...  \n",
       "2220       0              0.349427  \n",
       "2221       0              0.353183  \n",
       "2222       0              0.314981  \n",
       "2223       0              0.335836  \n",
       "2224       2              0.339601  \n",
       "\n",
       "[2225 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_pred_probas = topic_model.fit_transform(documents)\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "results_df['document'] = documents\n",
    "results_df['y_true'] = documents_df['class_name'].tolist()\n",
    "results_df['y_pred'] = y_pred_probas.argmax(axis=1)\n",
    "results_df['y_pred_highest_proba'] = y_pred_probas.max(axis=1)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_for_topics(topics: list):\n",
    "    \"\"\" Returns a dictionary with the words for each topic.\n",
    "\n",
    "    Args:\n",
    "        topics (list): List of topics. \n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with the words for each topic.\n",
    "    \"\"\"\n",
    "    words_by_topics = {}\n",
    "    for idx, topic in enumerate(topics):\n",
    "        words = documents_df.iloc[idx]['document'].split()\n",
    "\n",
    "        if topic not in words_by_topics:\n",
    "            words_by_topics[topic] = {}\n",
    "\n",
    "        for word in words:\n",
    "            if word not in words_by_topics[topic]:\n",
    "                words_by_topics[topic][word] = 0\n",
    "\n",
    "            words_by_topics[topic][word] += 1\n",
    "\n",
    "    return words_by_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(model_output)\n",
    "\n",
    "words_by_extracted_topics = get_words_for_topics(results_df['y_pred'].tolist())\n",
    "words_by_class = get_words_for_topics(results_df['y_true'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coherence (c_v)</th>\n",
       "      <th>Coherence (c_uci)</th>\n",
       "      <th>Coherence (c_npmi)</th>\n",
       "      <th>Coherence (u_mass)</th>\n",
       "      <th>Diversity</th>\n",
       "      <th>Supervised correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.458918</td>\n",
       "      <td>-5.598051</td>\n",
       "      <td>-0.201106</td>\n",
       "      <td>-3.319946</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.397752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Coherence (c_v)  Coherence (c_uci)  Coherence (c_npmi)  Coherence (u_mass)  \\\n",
       "0         0.458918          -5.598051           -0.201106           -3.319946   \n",
       "\n",
       "   Diversity  Supervised correlation  \n",
       "0       0.92                0.397752  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence = evaluator.compute_coherence()\n",
    "diversity = evaluator.compute_diversity()\n",
    "supervised_correlation = evaluator.compute_supervised_correlation(words_by_extracted_topics, words_by_class)\n",
    "\n",
    "metrics_df = pd.DataFrame()\n",
    "\n",
    "for coherence_type, coherence_value in coherence.items():\n",
    "    metrics_df[f'Coherence ({coherence_type})'] = [coherence_value]\n",
    "metrics_df['Diversity'] = [diversity]\n",
    "metrics_df['Supervised correlation'] = [supervised_correlation]\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: randomness + most important words as with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most important words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_top_words = 10\n",
    "x, y = 0, 0\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "\n",
    "# Plotting the important words by topics and their importance\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 12), sharey=True)\n",
    "fig.suptitle('Important words by topics and their importance', fontsize=18, fontweight='bold')\n",
    "\n",
    "for topic_idx, topic in enumerate(set(results_df['y_pred'].tolist())):\n",
    "    features = words_by_extracted_topics[topic].keys()\n",
    "    features_values = words_by_extracted_topics[topic].values()    \n",
    "    features = [x for _, x in sorted(zip(features_values, features), reverse=True)]\n",
    "\n",
    "    ax = axes[x, y]\n",
    "    ax.set_title(f'Topic {topic_idx}', fontsize=12, fontweight='bold')\n",
    "    ax.bar(features, features_values, color=colors[topic_idx])\n",
    "    ax.set_xlabel('Words')\n",
    "    ax.set_ylabel('Importance')\n",
    "    ax.xaxis.set_ticks(features)\n",
    "    ax.set_xticklabels(features, rotation=45, ha='right')\n",
    "\n",
    "    if y == 1:\n",
    "        x += 1\n",
    "        y = 0\n",
    "    else:\n",
    "        y += 1\n",
    "\n",
    "fig.delaxes(axes[2, 1])\n",
    "fig.tight_layout(pad=2.0, rect=[-0.02, -0.02, 1.02, 1])\n",
    "fig.savefig('../../figures/vontss/important_words_by_topics.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 5\n",
    "metrics_df = pd.DataFrame()\n",
    "\n",
    "for iter in range(n_iter):\n",
    "    topic_model = TopicModel(numb_embeddings=len(set(labels)))\n",
    "\n",
    "    model_output = topic_model.train_model(documents)\n",
    "    y_pred, y_pred_probas = topic_model.fit_transform(documents)\n",
    "\n",
    "    results_df = pd.DataFrame()\n",
    "    results_df['document'] = documents\n",
    "    results_df['y_true'] = documents_df['class_name'].tolist()\n",
    "    results_df['y_pred'] = y_pred_probas.argmax(axis=1)\n",
    "    results_df['y_pred_highest_proba'] = y_pred_probas.max(axis=1)\n",
    "\n",
    "    evaluator = Evaluator(model_output)\n",
    "\n",
    "    words_by_extracted_topics = get_words_for_topics(results_df['y_pred'].tolist())\n",
    "    words_by_class = get_words_for_topics(results_df['y_true'].tolist())\n",
    "\n",
    "    coherence = evaluator.compute_coherence()\n",
    "    diversity = evaluator.compute_diversity()\n",
    "    supervised_correlation = evaluator.compute_supervised_correlation(words_by_extracted_topics, words_by_class)\n",
    "\n",
    "    metrics_df_iter = pd.DataFrame()\n",
    "\n",
    "    for coherence_type, coherence_value in coherence.items():\n",
    "        metrics_df_iter[f'Coherence ({coherence_type})'] = [coherence_value]\n",
    "    metrics_df_iter['Diversity'] = [diversity]\n",
    "    metrics_df_iter['Supervised correlation'] = [supervised_correlation]\n",
    "\n",
    "    metrics_df = pd.concat([metrics_df, metrics_df_iter])\n",
    "\n",
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
